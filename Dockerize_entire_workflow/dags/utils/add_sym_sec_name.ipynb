{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/07/23 01:14:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "[PATH_NOT_FOUND] Path does not exist: file:/Users/hople/working_folder/Bootcamp_practices/ML_PIPELINE_AIRFLOW_SPARK_DOCKER/Dockerize_entire_workflow/dags/utils/path/to/stock_data.csv.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39m# Step 3: Read data from CSV into the DataFrame using the existing schema\u001b[39;00m\n\u001b[1;32m     19\u001b[0m file_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpath/to/stock_data.csv\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# Update this with the actual path of your CSV file\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m stock_df \u001b[39m=\u001b[39m spark\u001b[39m.\u001b[39;49mread\u001b[39m.\u001b[39;49mcsv(file_path, header\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, schema\u001b[39m=\u001b[39;49mexisting_schema)\n\u001b[1;32m     22\u001b[0m \u001b[39m# Step 4: Add new columns 'Symbol' and 'Security Name'\u001b[39;00m\n\u001b[1;32m     23\u001b[0m stock_df \u001b[39m=\u001b[39m stock_df\u001b[39m.\u001b[39mwithColumn(\u001b[39m\"\u001b[39m\u001b[39mSymbol\u001b[39m\u001b[39m\"\u001b[39m, StringType())  \u001b[39m# Fill in the 'Symbol' column with appropriate values\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/work_sample/lib/python3.10/site-packages/pyspark/sql/readwriter.py:727\u001b[0m, in \u001b[0;36mDataFrameReader.csv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(path) \u001b[39m==\u001b[39m \u001b[39mlist\u001b[39m:\n\u001b[1;32m    726\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_spark\u001b[39m.\u001b[39m_sc\u001b[39m.\u001b[39m_jvm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 727\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_df(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jreader\u001b[39m.\u001b[39;49mcsv(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_spark\u001b[39m.\u001b[39;49m_sc\u001b[39m.\u001b[39;49m_jvm\u001b[39m.\u001b[39;49mPythonUtils\u001b[39m.\u001b[39;49mtoSeq(path)))\n\u001b[1;32m    728\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, RDD):\n\u001b[1;32m    730\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mfunc\u001b[39m(iterator):\n",
      "File \u001b[0;32m/opt/miniconda3/envs/work_sample/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/miniconda3/envs/work_sample/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    171\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[1;32m    172\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    173\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [PATH_NOT_FOUND] Path does not exist: file:/Users/hople/working_folder/Bootcamp_practices/ML_PIPELINE_AIRFLOW_SPARK_DOCKER/Dockerize_entire_workflow/dags/utils/path/to/stock_data.csv."
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType\n",
    "\n",
    "# Step 1: Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"ETFs_Stocks_Data\").getOrCreate()\n",
    "\n",
    "# Step 2: Define the schema for the existing stock data without 'Symbol' and 'Security Name'\n",
    "existing_schema = StructType([\n",
    "    StructField(\"Date\", StringType(), True),\n",
    "    StructField(\"Open\", FloatType(), True),\n",
    "    StructField(\"High\", FloatType(), True),\n",
    "    StructField(\"Low\", FloatType(), True),\n",
    "    StructField(\"Close\", FloatType(), True),\n",
    "    StructField(\"Adj Close\", FloatType(), True),\n",
    "    StructField(\"Volume\", FloatType(), True)  # Assuming Volume is represented as a float type\n",
    "])\n",
    "\n",
    "# Step 3: Read data from CSV into the DataFrame using the existing schema\n",
    "file_path = \"path/to/stock_data.csv\"  # Update this with the actual path of your CSV file\n",
    "stock_df = spark.read.csv(file_path, header=True, schema=existing_schema)\n",
    "\n",
    "# Step 4: Add new columns 'Symbol' and 'Security Name'\n",
    "stock_df = stock_df.withColumn(\"Symbol\", StringType())  # Fill in the 'Symbol' column with appropriate values\n",
    "stock_df = stock_df.withColumn(\"Security Name\", StringType())  # Fill in the 'Security Name' column with appropriate values\n",
    "\n",
    "# Now, the 'stock_df' DataFrame contains your data with the 'Symbol' and 'Security Name' columns.\n",
    "# You can populate the values of 'Symbol' and 'Security Name' based on your data source.\n",
    "\n",
    "# Example of populating the 'Symbol' and 'Security Name' columns using a constant value for demonstration purposes:\n",
    "symbol_value = \"AAPL\"  # Replace this with the actual symbol value\n",
    "security_name_value = \"Apple Inc.\"  # Replace this with the actual security name value\n",
    "\n",
    "# To fill all rows in the column with a constant value, use the 'lit' function from 'pyspark.sql.functions':\n",
    "from pyspark.sql.functions import lit\n",
    "stock_df = stock_df.withColumn(\"Symbol\", lit(symbol_value))\n",
    "stock_df = stock_df.withColumn(\"Security Name\", lit(security_name_value))\n",
    "\n",
    "# Now, the 'stock_df' DataFrame has the 'Symbol' and 'Security Name' columns populated with the provided values.\n",
    "\n",
    "# Additional operations on the DataFrame, if required.\n",
    "# For example, you can save the DataFrame back to a new CSV file:\n",
    "output_file_path = \"path/to/output_stock_data.csv\"  # Replace this with the desired output file path\n",
    "stock_df.write.csv(output_file_path, header=True, mode=\"overwrite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = pd.read_csv('../data/stocks_etfs/A.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999-11-18</td>\n",
       "      <td>32.546494</td>\n",
       "      <td>35.765381</td>\n",
       "      <td>28.612303</td>\n",
       "      <td>31.473534</td>\n",
       "      <td>27.068665</td>\n",
       "      <td>62546300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999-11-19</td>\n",
       "      <td>30.713520</td>\n",
       "      <td>30.758226</td>\n",
       "      <td>28.478184</td>\n",
       "      <td>28.880543</td>\n",
       "      <td>24.838577</td>\n",
       "      <td>15234100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999-11-22</td>\n",
       "      <td>29.551144</td>\n",
       "      <td>31.473534</td>\n",
       "      <td>28.657009</td>\n",
       "      <td>31.473534</td>\n",
       "      <td>27.068665</td>\n",
       "      <td>6577800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999-11-23</td>\n",
       "      <td>30.400572</td>\n",
       "      <td>31.205294</td>\n",
       "      <td>28.612303</td>\n",
       "      <td>28.612303</td>\n",
       "      <td>24.607880</td>\n",
       "      <td>5975600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999-11-24</td>\n",
       "      <td>28.701717</td>\n",
       "      <td>29.998211</td>\n",
       "      <td>28.612303</td>\n",
       "      <td>29.372318</td>\n",
       "      <td>25.261524</td>\n",
       "      <td>4843200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5119</th>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>74.449997</td>\n",
       "      <td>69.650002</td>\n",
       "      <td>73.720001</td>\n",
       "      <td>73.532867</td>\n",
       "      <td>3267500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5120</th>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>71.550003</td>\n",
       "      <td>73.209999</td>\n",
       "      <td>70.279999</td>\n",
       "      <td>70.910004</td>\n",
       "      <td>70.730003</td>\n",
       "      <td>1829800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5121</th>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>71.059998</td>\n",
       "      <td>73.180000</td>\n",
       "      <td>71.059998</td>\n",
       "      <td>72.669998</td>\n",
       "      <td>72.669998</td>\n",
       "      <td>1486200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5122</th>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>72.339996</td>\n",
       "      <td>72.800003</td>\n",
       "      <td>70.500000</td>\n",
       "      <td>71.620003</td>\n",
       "      <td>71.620003</td>\n",
       "      <td>1822100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5123</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>69.470001</td>\n",
       "      <td>70.230003</td>\n",
       "      <td>68.150002</td>\n",
       "      <td>68.919998</td>\n",
       "      <td>68.919998</td>\n",
       "      <td>2173600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5124 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date       Open       High        Low      Close  Adj Close  \\\n",
       "0     1999-11-18  32.546494  35.765381  28.612303  31.473534  27.068665   \n",
       "1     1999-11-19  30.713520  30.758226  28.478184  28.880543  24.838577   \n",
       "2     1999-11-22  29.551144  31.473534  28.657009  31.473534  27.068665   \n",
       "3     1999-11-23  30.400572  31.205294  28.612303  28.612303  24.607880   \n",
       "4     1999-11-24  28.701717  29.998211  28.612303  29.372318  25.261524   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "5119  2020-03-26  70.000000  74.449997  69.650002  73.720001  73.532867   \n",
       "5120  2020-03-27  71.550003  73.209999  70.279999  70.910004  70.730003   \n",
       "5121  2020-03-30  71.059998  73.180000  71.059998  72.669998  72.669998   \n",
       "5122  2020-03-31  72.339996  72.800003  70.500000  71.620003  71.620003   \n",
       "5123  2020-04-01  69.470001  70.230003  68.150002  68.919998  68.919998   \n",
       "\n",
       "        Volume  \n",
       "0     62546300  \n",
       "1     15234100  \n",
       "2      6577800  \n",
       "3      5975600  \n",
       "4      4843200  \n",
       "...        ...  \n",
       "5119   3267500  \n",
       "5120   1829800  \n",
       "5121   1486200  \n",
       "5122   1822100  \n",
       "5123   2173600  \n",
       "\n",
       "[5124 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_p = pd.read_parquet('../data/processed_stocks_etfs/A.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Security Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>1999-11-18</td>\n",
       "      <td>32.546494</td>\n",
       "      <td>35.765381</td>\n",
       "      <td>28.612303</td>\n",
       "      <td>31.473534</td>\n",
       "      <td>27.068665</td>\n",
       "      <td>62546300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>1999-11-19</td>\n",
       "      <td>30.713520</td>\n",
       "      <td>30.758226</td>\n",
       "      <td>28.478184</td>\n",
       "      <td>28.880543</td>\n",
       "      <td>24.838577</td>\n",
       "      <td>15234100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>1999-11-22</td>\n",
       "      <td>29.551144</td>\n",
       "      <td>31.473534</td>\n",
       "      <td>28.657009</td>\n",
       "      <td>31.473534</td>\n",
       "      <td>27.068665</td>\n",
       "      <td>6577800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>1999-11-23</td>\n",
       "      <td>30.400572</td>\n",
       "      <td>31.205294</td>\n",
       "      <td>28.612303</td>\n",
       "      <td>28.612303</td>\n",
       "      <td>24.607880</td>\n",
       "      <td>5975600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>1999-11-24</td>\n",
       "      <td>28.701717</td>\n",
       "      <td>29.998211</td>\n",
       "      <td>28.612303</td>\n",
       "      <td>29.372318</td>\n",
       "      <td>25.261524</td>\n",
       "      <td>4843200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5119</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>74.449997</td>\n",
       "      <td>69.650002</td>\n",
       "      <td>73.720001</td>\n",
       "      <td>73.532867</td>\n",
       "      <td>3267500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5120</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>71.550003</td>\n",
       "      <td>73.209999</td>\n",
       "      <td>70.279999</td>\n",
       "      <td>70.910004</td>\n",
       "      <td>70.730003</td>\n",
       "      <td>1829800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5121</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>71.059998</td>\n",
       "      <td>73.180000</td>\n",
       "      <td>71.059998</td>\n",
       "      <td>72.669998</td>\n",
       "      <td>72.669998</td>\n",
       "      <td>1486200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5122</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>72.339996</td>\n",
       "      <td>72.800003</td>\n",
       "      <td>70.500000</td>\n",
       "      <td>71.620003</td>\n",
       "      <td>71.620003</td>\n",
       "      <td>1822100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5123</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>69.470001</td>\n",
       "      <td>70.230003</td>\n",
       "      <td>68.150002</td>\n",
       "      <td>68.919998</td>\n",
       "      <td>68.919998</td>\n",
       "      <td>2173600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5124 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Symbol                            Security Name        Date       Open  \\\n",
       "0         A  Agilent Technologies, Inc. Common Stock  1999-11-18  32.546494   \n",
       "1         A  Agilent Technologies, Inc. Common Stock  1999-11-19  30.713520   \n",
       "2         A  Agilent Technologies, Inc. Common Stock  1999-11-22  29.551144   \n",
       "3         A  Agilent Technologies, Inc. Common Stock  1999-11-23  30.400572   \n",
       "4         A  Agilent Technologies, Inc. Common Stock  1999-11-24  28.701717   \n",
       "...     ...                                      ...         ...        ...   \n",
       "5119      A  Agilent Technologies, Inc. Common Stock  2020-03-26  70.000000   \n",
       "5120      A  Agilent Technologies, Inc. Common Stock  2020-03-27  71.550003   \n",
       "5121      A  Agilent Technologies, Inc. Common Stock  2020-03-30  71.059998   \n",
       "5122      A  Agilent Technologies, Inc. Common Stock  2020-03-31  72.339996   \n",
       "5123      A  Agilent Technologies, Inc. Common Stock  2020-04-01  69.470001   \n",
       "\n",
       "           High        Low      Close  Adj Close    Volume  \n",
       "0     35.765381  28.612303  31.473534  27.068665  62546300  \n",
       "1     30.758226  28.478184  28.880543  24.838577  15234100  \n",
       "2     31.473534  28.657009  31.473534  27.068665   6577800  \n",
       "3     31.205294  28.612303  28.612303  24.607880   5975600  \n",
       "4     29.998211  28.612303  29.372318  25.261524   4843200  \n",
       "...         ...        ...        ...        ...       ...  \n",
       "5119  74.449997  69.650002  73.720001  73.532867   3267500  \n",
       "5120  73.209999  70.279999  70.910004  70.730003   1829800  \n",
       "5121  73.180000  71.059998  72.669998  72.669998   1486200  \n",
       "5122  72.800003  70.500000  71.620003  71.620003   1822100  \n",
       "5123  70.230003  68.150002  68.919998  68.919998   2173600  \n",
       "\n",
       "[5124 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work_sample",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
