{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PySpark Version : 3.4.1\n",
      "Number of CPU: 8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, IntegerType\n",
    "from pyspark.sql.functions import input_file_name, lit, col, isnull\n",
    "from pyspark.sql import functions as F\n",
    "print(f\"PySpark Version : {pyspark.__version__}\")\n",
    "import multiprocessing\n",
    "print(f\"Number of CPU: {multiprocessing.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/28 22:22:22 WARN Utils: Your hostname, Hops-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.0.140 instead (on interface en0)\n",
      "23/07/28 22:22:22 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/07/28 22:22:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "#Create a spark Context class, with custom config\n",
    "conf = SparkConf()\n",
    "conf.set('spark.default.parallelism', 700)\n",
    "conf.set('spark.sql.shuffle.partitions', 700)\n",
    "conf.set('spark.driver.memory', '30g')\n",
    "conf.set('spark.driver.cores', 8)\n",
    "conf.set('spark.executor.cores', 8)\n",
    "conf.set('spark.executor.memory', '30g')\n",
    "sc = SparkContext.getOrCreate(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create spark session\n",
    "spark = SparkSession.builder.master('local[*]').\\\n",
    "                config('spark.sql.debug.maxToStringFields', '100').\\\n",
    "                appName(\"ETFs Spark Airflow Docker\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparksession import initilize_sparksession\n",
    "\n",
    "spark = initilize_sparksession()\n",
    "existing_schema = StructType([\n",
    "    StructField(\"Date\", StringType(), False),\n",
    "    StructField(\"Open\", FloatType(), False),\n",
    "    StructField(\"High\", FloatType(), False),\n",
    "    StructField(\"Low\", FloatType(), False),\n",
    "    StructField(\"Close\", FloatType(), False),\n",
    "    StructField(\"Adj Close\", FloatType(), False),\n",
    "    StructField(\"Volume\", FloatType(), False),\n",
    "    StructField(\"Symbol\", FloatType(), False),\n",
    "    StructField(\"Security Name\", FloatType(), False)\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"../data/stocks_etfs/A.csv\"\n",
    "stock_df = spark.read.csv(input_path, header=True, schema=existing_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Open: float (nullable = true)\n",
      " |-- High: float (nullable = true)\n",
      " |-- Low: float (nullable = true)\n",
      " |-- Close: float (nullable = true)\n",
      " |-- Adj Close: float (nullable = true)\n",
      " |-- Volume: float (nullable = true)\n",
      " |-- Symbol: float (nullable = true)\n",
      " |-- Security Name: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stock_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_symbol = spark.read.csv(\"../data/symbols_valid_meta.csv\", header=True)\n",
    "symbol_mapping = meta_symbol.select(\"Symbol\", \"Security Name\").rdd.collectAsMap()\n",
    "symbol_name = os.path.splitext(os.path.basename(input_path))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+---------+---------+---------+---------+------+-------------+\n",
      "|      Date|     Open|     High|      Low|    Close|Adj Close|   Volume|Symbol|Security Name|\n",
      "+----------+---------+---------+---------+---------+---------+---------+------+-------------+\n",
      "|1999-11-18|32.546494| 35.76538|28.612303|31.473534|27.068665|6.25463E7|  null|         null|\n",
      "|1999-11-19| 30.71352|30.758226|28.478184|28.880543|24.838577|1.52341E7|  null|         null|\n",
      "|1999-11-22|29.551144|31.473534| 28.65701|31.473534|27.068665|6577800.0|  null|         null|\n",
      "|1999-11-23|30.400572|31.205294|28.612303|28.612303| 24.60788|5975600.0|  null|         null|\n",
      "|1999-11-24|28.701717| 29.99821|28.612303|29.372318|25.261524|4843200.0|  null|         null|\n",
      "|1999-11-26|29.238197|29.685265|29.148785|29.461731|25.338428|1729400.0|  null|         null|\n",
      "|1999-11-29| 29.32761|30.355865|29.014664|30.132332|25.915169|4074700.0|  null|         null|\n",
      "|1999-11-30| 30.04292| 30.71352|29.282904|30.177038|25.953619|4310000.0|  null|         null|\n",
      "|1999-12-01|30.177038|31.071173|29.953505| 30.71352|26.415012|2957300.0|  null|         null|\n",
      "|1999-12-02|31.294706|32.188843|30.892345|31.562946|27.145563|3069800.0|  null|         null|\n",
      "+----------+---------+---------+---------+---------+---------+---------+------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/26 01:25:58 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 7, schema size: 9\n",
      "CSV file: file:///Users/hople/working_folder/Bootcamp_practices/ML_PIPELINE_AIRFLOW_SPARK_DOCKER/Dockerize_entire_workflow/dags/data/stocks_etfs/A.csv\n"
     ]
    }
   ],
   "source": [
    "stock_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_df = stock_df.withColumn(\"Symbol\", F.lit(symbol_name))\n",
    "stock_df = stock_df.withColumn(\"Security Name\", F.lit(symbol_mapping.get(symbol_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_df.write.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+---------+---------+---------+---------+------+--------------------+\n",
      "|      Date|     Open|     High|      Low|    Close|Adj Close|   Volume|Symbol|       Security Name|\n",
      "+----------+---------+---------+---------+---------+---------+---------+------+--------------------+\n",
      "|1999-11-18|32.546494| 35.76538|28.612303|31.473534|27.068665|6.25463E7|     A|Agilent Technolog...|\n",
      "|1999-11-19| 30.71352|30.758226|28.478184|28.880543|24.838577|1.52341E7|     A|Agilent Technolog...|\n",
      "|1999-11-22|29.551144|31.473534| 28.65701|31.473534|27.068665|6577800.0|     A|Agilent Technolog...|\n",
      "|1999-11-23|30.400572|31.205294|28.612303|28.612303| 24.60788|5975600.0|     A|Agilent Technolog...|\n",
      "|1999-11-24|28.701717| 29.99821|28.612303|29.372318|25.261524|4843200.0|     A|Agilent Technolog...|\n",
      "|1999-11-26|29.238197|29.685265|29.148785|29.461731|25.338428|1729400.0|     A|Agilent Technolog...|\n",
      "|1999-11-29| 29.32761|30.355865|29.014664|30.132332|25.915169|4074700.0|     A|Agilent Technolog...|\n",
      "|1999-11-30| 30.04292| 30.71352|29.282904|30.177038|25.953619|4310000.0|     A|Agilent Technolog...|\n",
      "|1999-12-01|30.177038|31.071173|29.953505| 30.71352|26.415012|2957300.0|     A|Agilent Technolog...|\n",
      "|1999-12-02|31.294706|32.188843|30.892345|31.562946|27.145563|3069800.0|     A|Agilent Technolog...|\n",
      "+----------+---------+---------+---------+---------+---------+---------+------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stock_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Security Name: string]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_df.select(\"Security Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Open: float (nullable = true)\n",
      " |-- High: float (nullable = true)\n",
      " |-- Low: float (nullable = true)\n",
      " |-- Close: float (nullable = true)\n",
      " |-- Adj Close: float (nullable = true)\n",
      " |-- Volume: float (nullable = true)\n",
      " |-- Symbol: string (nullable = false)\n",
      " |-- Security Name: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stock_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from save_parquet import save_parquet\n",
    "import os\n",
    "\n",
    "#retain features columns\n",
    "features = ['Symbol', 'Security Name', 'Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
    "#path to save processed dataset\n",
    "path = '../data/processed_stocks_etfs/'\n",
    "#read metal symbol files\n",
    "metal_symbol = pd.read_csv('../data/symbols_valid_meta.csv')\n",
    "metal_symbol = metal_symbol[['Symbol', 'Security Name']]\n",
    "#correct some wrong spelling, coresponding to Stock file name\n",
    "metal_symbol['Symbol'] = metal_symbol['Symbol'].str.replace('$', '-',regex=False)\n",
    "metal_symbol['Symbol'] = metal_symbol['Symbol'].str.replace('.V', '',regex=False)\n",
    "#creat mapping dictionary\n",
    "symbol_mapping = metal_symbol.set_index('Symbol').to_dict()['Security Name']\n",
    "\n",
    "def add_name(file):\n",
    "    #print(symbol_mapping)\n",
    "    name = os.path.splitext(os.path.basename(file))[0]\n",
    "    df = pd.read_csv(file)\n",
    "    df['Symbol'] = name\n",
    "    sec_name = symbol_mapping[name]\n",
    "    df['Security Name'] = sec_name\n",
    "    #print(sec_name)\n",
    "    #df.name = name\n",
    "    #return df\n",
    "    save_parquet(df[features], name, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count\n",
    "\n",
    "stocks_path = '../data/stocks_etfs/'\n",
    "#path = '../data/processed_stocks_etfs/'\n",
    "from load_files import load_file\n",
    "#list of loaded csv files will split into n_processor, for parralezation process\n",
    "n_processor = cpu_count()\n",
    "#get batches of data, list of list\n",
    "preprocessing_list = load_file(n_processor, stocks_path, 'csv')\n",
    "\n",
    "\n",
    "def data_processing():\n",
    "    '''\n",
    "    Takes batch number as input\n",
    "    Map function add_name for every dataframe in batch number in preprocessing_list\n",
    "    '''\n",
    "    temp = list(map(add_name, preprocessing_list))\n",
    "\n",
    "#data_processing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/07/28 01:06:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql import functions as F\n",
    "import os\n",
    "from multiprocessing import cpu_count\n",
    "from load_files import load_file #function load files into batches\n",
    "\n",
    "#Create a spark Context class, with custom config to optimize the performance\n",
    "#conf.set('spark.sql.adaptive.coalescePartitions.initialPartitionNum', 24)\n",
    "#conf.set('spark.sql.adaptive.coalescePartitions.parallelismFirst', 'false')\n",
    "#conf.set('spark.sql.files.minPartitionNum', 1)\n",
    "conf = SparkConf()\n",
    "conf.set('spark.default.parallelism', 700)\n",
    "conf.set('spark.sql.shuffle.partitions', 700)\n",
    "#conf.set('spark.sql.files.maxPartitionBytes', '500mb')\n",
    "conf.set('spark.driver.memory', '30g')\n",
    "conf.set('spark.driver.cores', 8)\n",
    "conf.set('spark.executor.cores', 8)\n",
    "conf.set('spark.executor.memory', '30g')\n",
    "sc = SparkContext.getOrCreate(conf)\n",
    "\n",
    "## Initialize SparkSession\n",
    "spark = SparkSession.builder.master('local[*]').\\\n",
    "                config('spark.sql.debug.maxToStringFields', '100').\\\n",
    "                appName(\"ETFs Spark Airflow Docker\").getOrCreate()\n",
    "\n",
    "\n",
    "#stock dir\n",
    "stocks_dir = \"../data/stocks_etfs\"\n",
    "#processed data dir\n",
    "processed_stocks_dir = \"../data/processed_stocks_etfs\"\n",
    "\n",
    "#Mapping dict\n",
    "meta_symbol = spark.read.csv(\"../data/symbols_valid_meta.csv\", header=True)\n",
    "symbol_mapping = meta_symbol.select(\"Symbol\", \"Security Name\").rdd.collectAsMap()\n",
    "\n",
    "#Define Schema for the data\n",
    "existing_schema = StructType([\n",
    "    StructField(\"Date\", StringType(), False),\n",
    "    StructField(\"Open\", FloatType(), False),\n",
    "    StructField(\"High\", FloatType(), False),\n",
    "    StructField(\"Low\", FloatType(), False),\n",
    "    StructField(\"Close\", FloatType(), False),\n",
    "    StructField(\"Adj Close\", FloatType(), False),\n",
    "    StructField(\"Volume\", FloatType(), False),\n",
    "    StructField(\"Symbol\", FloatType(), False),\n",
    "    StructField(\"Security Name\", FloatType(), False)\n",
    "\n",
    "])\n",
    "\n",
    "def add_sym_sec_name(input_file):\n",
    "    \"\"\"\n",
    "    Function adds Symbol and Security Name to stock file\n",
    "    \"\"\"\n",
    "    # Read data from CSV into the DataFrame using the existing schema\n",
    "    stock_df = spark.read.csv(input_file, header=True, schema=existing_schema)\n",
    "\n",
    "    # Get Symbol name from input file\n",
    "    symbol_name = os.path.splitext(os.path.basename(input_file))[0]\n",
    "\n",
    "    # Adding Symbol and Security Name\n",
    "    stock_df = stock_df.withColumn(\"Symbol\", F.lit(symbol_name))\n",
    "    stock_df = stock_df.withColumn(\"Security Name\", F.lit(symbol_mapping.get(symbol_name)))\n",
    "\n",
    "    # Save the preprocessed data to a parquet file\n",
    "    #output_file = os.path.join(processed_stocks_dir, f\"{symbol_name}_preprocessed.parquet\")\n",
    "    output_file = f\"{processed_stocks_dir}/{symbol_name}_preprocessed.parquet\"\n",
    "    stock_df.write.parquet(output_file, mode=\"overwrite\")\n",
    "\n",
    "\n",
    "def preprocessing_data():\n",
    "    '''\n",
    "    Takes batch number as input\n",
    "    Map function add_sym_sec_name for every dataframe in batch number in preprocessing_list\n",
    "    '''\n",
    "    #list of loaded csv files will split into n_processor, for parralezation process in Airflow\n",
    "    n_processor = cpu_count()\n",
    "    #get batches of data\n",
    "    preprocessing_list = load_file(n_processor, stocks_dir, 'csv')\n",
    "    #temp = list(map(add_sym_sec_name, ('../data/stocks_etfs/A.csv')))\n",
    "    #print(preprocessing_list)\n",
    "\n",
    "preprocessing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessing_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mstr\u001b[39m(preprocessing_list[\u001b[39m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocessing_list' is not defined"
     ]
    }
   ],
   "source": [
    "str(preprocessing_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+----------+----------+----------+--------+------+-------------+\n",
      "|      Date|      Open|      High|       Low|     Close| Adj Close|  Volume|Symbol|Security Name|\n",
      "+----------+----------+----------+----------+----------+----------+--------+------+-------------+\n",
      "|1988-02-04|       0.0|0.61728394| 0.5555556| 0.5555556|0.42403868| 38700.0|  null|         null|\n",
      "|1988-02-05|       0.0|0.61728394| 0.5555556| 0.5555556|0.42403868|606300.0|  null|         null|\n",
      "|1988-02-08|       0.0|0.61728394| 0.5555556| 0.5555556|0.42403868| 19000.0|  null|         null|\n",
      "|1988-02-09|       0.0|0.61728394| 0.5555556| 0.5555556|0.42403868| 23100.0|  null|         null|\n",
      "|1988-02-10|       0.0|0.61728394| 0.5555556| 0.5555556|0.42403868| 10000.0|  null|         null|\n",
      "|1988-02-11|       0.0|0.61728394| 0.5555556| 0.5555556|0.42403868| 10900.0|  null|         null|\n",
      "|1988-02-12|       0.0|0.61728394| 0.5555556| 0.5555556|0.42403868|     0.0|  null|         null|\n",
      "|1988-02-16|       0.0|0.61728394|0.52469134|0.52469134|0.40048075| 66700.0|  null|         null|\n",
      "|1988-02-17|0.52469134|0.52469134|0.52469134|0.52469134|0.40048075|     0.0|  null|         null|\n",
      "|1988-02-18|       0.0|0.61728394|0.49382716|0.49382716| 0.3769232| 21100.0|  null|         null|\n",
      "+----------+----------+----------+----------+----------+----------+--------+------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/28 00:37:48 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 7, schema size: 9\n",
      "CSV file: file:///Users/hople/working_folder/ML_PIPELINE_AIRFLOW_SPARK_DOCKER/dags/data/stocks_etfs/IPAR.csv\n"
     ]
    }
   ],
   "source": [
    "spark.read.csv(str(preprocessing_list[0]), header=True, schema=existing_schema).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AAL_preprocessed'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from load_files import load_file\n",
    "from multiprocessing import cpu_count\n",
    "stocks_dir = '../data/stocks_etfs/'\n",
    "n_processor = cpu_count()\n",
    "#get batches of data\n",
    "preprocessing_list = load_file(n_processor, '../data/processed_stocks_etfs/', 'parquet')\n",
    "\n",
    "preprocessing_list[0][0].stem\n",
    "#pd.read_parquet(preprocessing_list[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparksession import initilize_sparksession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, DateType\n",
    "from pyspark.sql import functions as F\n",
    "spark = initilize_sparksession()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_stock = spark.read.parquet('../data/processed_stocks_etfs/A_preprocessed.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Symbol: string (nullable = true)\n",
      " |-- Security Name: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Open: float (nullable = true)\n",
      " |-- High: float (nullable = true)\n",
      " |-- Low: float (nullable = true)\n",
      " |-- Close: float (nullable = true)\n",
      " |-- Adj Close: float (nullable = true)\n",
      " |-- Volume: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processed_stock.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 60:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+----------+---------+---------+---------+---------+---------+---------+--------------+---------------------+\n",
      "|Symbol|       Security Name|      Date|     Open|     High|      Low|    Close|Adj Close|   Volume|vol_moving_avg|adj_close_rolling_med|\n",
      "+------+--------------------+----------+---------+---------+---------+---------+---------+---------+--------------+---------------------+\n",
      "|     A|Agilent Technolog...|1999-12-31| 56.86695|  57.1799|54.542202|55.302216|47.562416|1931100.0|     5739950.0|            2937500.0|\n",
      "|     A|Agilent Technolog...|2000-01-03| 56.33047|56.464592|48.193848|51.502148| 44.29417|4674300.0|     3810883.0|            2937500.0|\n",
      "|     A|Agilent Technolog...|2000-01-04|48.730328| 49.26681|46.316166|47.567955| 40.91059|4765000.0|     3461913.0|            2937500.0|\n",
      "|     A|Agilent Technolog...|2000-01-05|47.389126|47.567955|43.141987| 44.61731|38.372894|5758600.0|     3434607.0|            2937500.0|\n",
      "|     A|Agilent Technolog...|2000-01-06| 44.08083| 44.34907| 41.57725|42.918453|36.911816|2534400.0|     3319900.0|            2750800.0|\n",
      "|     A|Agilent Technolog...|2000-01-07|42.247852|47.165592|42.203148| 46.49499|39.987797|2819600.0|     3252447.0|            2701750.0|\n",
      "|     A|Agilent Technolog...|2000-01-10|49.356224| 49.80329| 48.32797|49.311516|42.410137|2148400.0|     3266413.0|            2701750.0|\n",
      "|     A|Agilent Technolog...|2000-01-11|49.311516|49.311516|47.523247|48.640915|41.833397|1855900.0|     3192453.0|            2559150.0|\n",
      "|     A|Agilent Technolog...|2000-01-12|48.640915|48.640915| 45.82439|47.657368|40.987488|1429800.0|     3096447.0|            2431650.0|\n",
      "|     A|Agilent Technolog...|2000-01-13|48.909157|49.937412|  47.2103|48.372677|41.602703|1134300.0|     3035680.0|            2294150.0|\n",
      "+------+--------------------+----------+---------+---------+---------+---------+---------+---------+--------------+---------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "processed_stock.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate volume moving average using Window function for the last 30 days, including the current row\n",
    "w_date = Window.partitionBy(F.lit(0)).orderBy(F.col('Date')).rowsBetween(-29, 0)\n",
    "processed_stock = processed_stock.withColumn('vol_moving_avg', F.mean('Volume').over(w_date))\n",
    "processed_stock = processed_stock.withColumn('vol_moving_avg', F.round('vol_moving_avg', 0))\n",
    "# Calculate the rolling median for the 'Volume' column over the last 30 days\n",
    "processed_stock = processed_stock.withColumn('adj_close_rolling_med', F.expr('percentile(Volume, 0.5)').over(w_date))\n",
    "processed_stock = processed_stock.withColumn('adj_close_rolling_med', F.round('adj_close_rolling_med', 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the first 30 days\n",
    "processed_stock = processed_stock.withColumn(\"counter\", F.monotonically_increasing_id())\n",
    "w_counter = Window.partitionBy(F.lit(0)).orderBy(\"counter\")\n",
    "processed_stock = processed_stock.withColumn(\"index\", F.row_number().over(w_counter))\n",
    "processed_stock = processed_stock.filter(F.col(\"index\") >= 30)\n",
    "processed_stock = processed_stock.drop(\"counter\", \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Project [Symbol#767, Security Name#768, Date#769, Open#770, High#771, Low#772, Close#773, Adj Close#774, Volume#775, round(vol_moving_avg#824, 0) AS vol_moving_avg#835, round(adj_close_rolling_med#846, 0) AS adj_close_rolling_med#859]\n",
      "   +- Window [avg(Volume#775) windowspecdefinition(0, Date#769 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -29, currentrow$())) AS vol_moving_avg#824, percentile_approx(Volume#775, 0.5, 10000, 0, 0) windowspecdefinition(0, Date#769 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -29, currentrow$())) AS adj_close_rolling_med#846], [0], [Date#769 ASC NULLS FIRST]\n",
      "      +- Sort [0 ASC NULLS FIRST, Date#769 ASC NULLS FIRST], false, 0\n",
      "         +- Exchange hashpartitioning(0, 8), ENSURE_REQUIREMENTS, [plan_id=896]\n",
      "            +- FileScan parquet [Symbol#767,Security Name#768,Date#769,Open#770,High#771,Low#772,Close#773,Adj Close#774,Volume#775] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/Users/hople/working_folder/ML_PIPELINE_AIRFLOW_SPARK_DOCKER/dags..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Symbol:string,Security Name:string,Date:string,Open:float,High:float,Low:float,Close:float...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processed_stock.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Security Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>vol_moving_avg</th>\n",
       "      <th>adj_close_rolling_med</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>56.866951</td>\n",
       "      <td>57.179901</td>\n",
       "      <td>54.542202</td>\n",
       "      <td>55.302216</td>\n",
       "      <td>47.562416</td>\n",
       "      <td>1931100.0</td>\n",
       "      <td>5739950.0</td>\n",
       "      <td>2937500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>56.330471</td>\n",
       "      <td>56.464592</td>\n",
       "      <td>48.193848</td>\n",
       "      <td>51.502148</td>\n",
       "      <td>44.294170</td>\n",
       "      <td>4674300.0</td>\n",
       "      <td>3810883.0</td>\n",
       "      <td>2937500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>48.730328</td>\n",
       "      <td>49.266811</td>\n",
       "      <td>46.316166</td>\n",
       "      <td>47.567955</td>\n",
       "      <td>40.910591</td>\n",
       "      <td>4765000.0</td>\n",
       "      <td>3461913.0</td>\n",
       "      <td>2937500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>47.389126</td>\n",
       "      <td>47.567955</td>\n",
       "      <td>43.141987</td>\n",
       "      <td>44.617310</td>\n",
       "      <td>38.372894</td>\n",
       "      <td>5758600.0</td>\n",
       "      <td>3434607.0</td>\n",
       "      <td>2937500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>44.080830</td>\n",
       "      <td>44.349072</td>\n",
       "      <td>41.577251</td>\n",
       "      <td>42.918453</td>\n",
       "      <td>36.911816</td>\n",
       "      <td>2534400.0</td>\n",
       "      <td>3319900.0</td>\n",
       "      <td>2750800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>42.247852</td>\n",
       "      <td>47.165592</td>\n",
       "      <td>42.203148</td>\n",
       "      <td>46.494991</td>\n",
       "      <td>39.987797</td>\n",
       "      <td>2819600.0</td>\n",
       "      <td>3252447.0</td>\n",
       "      <td>2701750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-01-10</td>\n",
       "      <td>49.356224</td>\n",
       "      <td>49.803291</td>\n",
       "      <td>48.327969</td>\n",
       "      <td>49.311516</td>\n",
       "      <td>42.410137</td>\n",
       "      <td>2148400.0</td>\n",
       "      <td>3266413.0</td>\n",
       "      <td>2701750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-01-11</td>\n",
       "      <td>49.311516</td>\n",
       "      <td>49.311516</td>\n",
       "      <td>47.523247</td>\n",
       "      <td>48.640915</td>\n",
       "      <td>41.833397</td>\n",
       "      <td>1855900.0</td>\n",
       "      <td>3192453.0</td>\n",
       "      <td>2559150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-01-12</td>\n",
       "      <td>48.640915</td>\n",
       "      <td>48.640915</td>\n",
       "      <td>45.824390</td>\n",
       "      <td>47.657368</td>\n",
       "      <td>40.987488</td>\n",
       "      <td>1429800.0</td>\n",
       "      <td>3096447.0</td>\n",
       "      <td>2431650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-01-13</td>\n",
       "      <td>48.909157</td>\n",
       "      <td>49.937412</td>\n",
       "      <td>47.210300</td>\n",
       "      <td>48.372677</td>\n",
       "      <td>41.602703</td>\n",
       "      <td>1134300.0</td>\n",
       "      <td>3035680.0</td>\n",
       "      <td>2294150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-01-14</td>\n",
       "      <td>47.925610</td>\n",
       "      <td>49.624462</td>\n",
       "      <td>47.925610</td>\n",
       "      <td>48.909157</td>\n",
       "      <td>42.064091</td>\n",
       "      <td>1316900.0</td>\n",
       "      <td>2977250.0</td>\n",
       "      <td>2255050.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Symbol                            Security Name        Date       Open  \\\n",
       "29      A  Agilent Technologies, Inc. Common Stock  1999-12-31  56.866951   \n",
       "30      A  Agilent Technologies, Inc. Common Stock  2000-01-03  56.330471   \n",
       "31      A  Agilent Technologies, Inc. Common Stock  2000-01-04  48.730328   \n",
       "32      A  Agilent Technologies, Inc. Common Stock  2000-01-05  47.389126   \n",
       "33      A  Agilent Technologies, Inc. Common Stock  2000-01-06  44.080830   \n",
       "34      A  Agilent Technologies, Inc. Common Stock  2000-01-07  42.247852   \n",
       "35      A  Agilent Technologies, Inc. Common Stock  2000-01-10  49.356224   \n",
       "36      A  Agilent Technologies, Inc. Common Stock  2000-01-11  49.311516   \n",
       "37      A  Agilent Technologies, Inc. Common Stock  2000-01-12  48.640915   \n",
       "38      A  Agilent Technologies, Inc. Common Stock  2000-01-13  48.909157   \n",
       "39      A  Agilent Technologies, Inc. Common Stock  2000-01-14  47.925610   \n",
       "\n",
       "         High        Low      Close  Adj Close     Volume  vol_moving_avg  \\\n",
       "29  57.179901  54.542202  55.302216  47.562416  1931100.0       5739950.0   \n",
       "30  56.464592  48.193848  51.502148  44.294170  4674300.0       3810883.0   \n",
       "31  49.266811  46.316166  47.567955  40.910591  4765000.0       3461913.0   \n",
       "32  47.567955  43.141987  44.617310  38.372894  5758600.0       3434607.0   \n",
       "33  44.349072  41.577251  42.918453  36.911816  2534400.0       3319900.0   \n",
       "34  47.165592  42.203148  46.494991  39.987797  2819600.0       3252447.0   \n",
       "35  49.803291  48.327969  49.311516  42.410137  2148400.0       3266413.0   \n",
       "36  49.311516  47.523247  48.640915  41.833397  1855900.0       3192453.0   \n",
       "37  48.640915  45.824390  47.657368  40.987488  1429800.0       3096447.0   \n",
       "38  49.937412  47.210300  48.372677  41.602703  1134300.0       3035680.0   \n",
       "39  49.624462  47.925610  48.909157  42.064091  1316900.0       2977250.0   \n",
       "\n",
       "    adj_close_rolling_med  \n",
       "29              2937500.0  \n",
       "30              2937500.0  \n",
       "31              2937500.0  \n",
       "32              2937500.0  \n",
       "33              2750800.0  \n",
       "34              2701750.0  \n",
       "35              2701750.0  \n",
       "36              2559150.0  \n",
       "37              2431650.0  \n",
       "38              2294150.0  \n",
       "39              2255050.0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_stock.limit(40).toPandas().iloc[29:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Security Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>vol_moving_avg</th>\n",
       "      <th>adj_close_rolling_med</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>56.866951</td>\n",
       "      <td>57.179901</td>\n",
       "      <td>54.542202</td>\n",
       "      <td>55.302216</td>\n",
       "      <td>47.562416</td>\n",
       "      <td>1931100</td>\n",
       "      <td>5.739950e+06</td>\n",
       "      <td>2937500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>56.330471</td>\n",
       "      <td>56.464592</td>\n",
       "      <td>48.193848</td>\n",
       "      <td>51.502148</td>\n",
       "      <td>44.294170</td>\n",
       "      <td>4674300</td>\n",
       "      <td>3.810883e+06</td>\n",
       "      <td>2937500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>48.730328</td>\n",
       "      <td>49.266811</td>\n",
       "      <td>46.316166</td>\n",
       "      <td>47.567955</td>\n",
       "      <td>40.910591</td>\n",
       "      <td>4765000</td>\n",
       "      <td>3.461913e+06</td>\n",
       "      <td>2937500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>47.389126</td>\n",
       "      <td>47.567955</td>\n",
       "      <td>43.141987</td>\n",
       "      <td>44.617310</td>\n",
       "      <td>38.372894</td>\n",
       "      <td>5758600</td>\n",
       "      <td>3.434607e+06</td>\n",
       "      <td>2937500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>44.080830</td>\n",
       "      <td>44.349072</td>\n",
       "      <td>41.577251</td>\n",
       "      <td>42.918453</td>\n",
       "      <td>36.911816</td>\n",
       "      <td>2534400</td>\n",
       "      <td>3.319900e+06</td>\n",
       "      <td>2750800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>42.247852</td>\n",
       "      <td>47.165592</td>\n",
       "      <td>42.203148</td>\n",
       "      <td>46.494991</td>\n",
       "      <td>39.987797</td>\n",
       "      <td>2819600</td>\n",
       "      <td>3.252447e+06</td>\n",
       "      <td>2701750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-01-10</td>\n",
       "      <td>49.356224</td>\n",
       "      <td>49.803291</td>\n",
       "      <td>48.327969</td>\n",
       "      <td>49.311516</td>\n",
       "      <td>42.410137</td>\n",
       "      <td>2148400</td>\n",
       "      <td>3.266413e+06</td>\n",
       "      <td>2701750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-01-11</td>\n",
       "      <td>49.311516</td>\n",
       "      <td>49.311516</td>\n",
       "      <td>47.523247</td>\n",
       "      <td>48.640915</td>\n",
       "      <td>41.833397</td>\n",
       "      <td>1855900</td>\n",
       "      <td>3.192453e+06</td>\n",
       "      <td>2559150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-01-12</td>\n",
       "      <td>48.640915</td>\n",
       "      <td>48.640915</td>\n",
       "      <td>45.824390</td>\n",
       "      <td>47.657368</td>\n",
       "      <td>40.987488</td>\n",
       "      <td>1429800</td>\n",
       "      <td>3.096447e+06</td>\n",
       "      <td>2431650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-01-13</td>\n",
       "      <td>48.909157</td>\n",
       "      <td>49.937412</td>\n",
       "      <td>47.210300</td>\n",
       "      <td>48.372677</td>\n",
       "      <td>41.602703</td>\n",
       "      <td>1134300</td>\n",
       "      <td>3.035680e+06</td>\n",
       "      <td>2294150.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Symbol                            Security Name       Date       Open  \\\n",
       "29      A  Agilent Technologies, Inc. Common Stock 1999-12-31  56.866951   \n",
       "30      A  Agilent Technologies, Inc. Common Stock 2000-01-03  56.330471   \n",
       "31      A  Agilent Technologies, Inc. Common Stock 2000-01-04  48.730328   \n",
       "32      A  Agilent Technologies, Inc. Common Stock 2000-01-05  47.389126   \n",
       "33      A  Agilent Technologies, Inc. Common Stock 2000-01-06  44.080830   \n",
       "34      A  Agilent Technologies, Inc. Common Stock 2000-01-07  42.247852   \n",
       "35      A  Agilent Technologies, Inc. Common Stock 2000-01-10  49.356224   \n",
       "36      A  Agilent Technologies, Inc. Common Stock 2000-01-11  49.311516   \n",
       "37      A  Agilent Technologies, Inc. Common Stock 2000-01-12  48.640915   \n",
       "38      A  Agilent Technologies, Inc. Common Stock 2000-01-13  48.909157   \n",
       "\n",
       "         High        Low      Close  Adj Close   Volume  vol_moving_avg  \\\n",
       "29  57.179901  54.542202  55.302216  47.562416  1931100    5.739950e+06   \n",
       "30  56.464592  48.193848  51.502148  44.294170  4674300    3.810883e+06   \n",
       "31  49.266811  46.316166  47.567955  40.910591  4765000    3.461913e+06   \n",
       "32  47.567955  43.141987  44.617310  38.372894  5758600    3.434607e+06   \n",
       "33  44.349072  41.577251  42.918453  36.911816  2534400    3.319900e+06   \n",
       "34  47.165592  42.203148  46.494991  39.987797  2819600    3.252447e+06   \n",
       "35  49.803291  48.327969  49.311516  42.410137  2148400    3.266413e+06   \n",
       "36  49.311516  47.523247  48.640915  41.833397  1855900    3.192453e+06   \n",
       "37  48.640915  45.824390  47.657368  40.987488  1429800    3.096447e+06   \n",
       "38  49.937412  47.210300  48.372677  41.602703  1134300    3.035680e+06   \n",
       "\n",
       "    adj_close_rolling_med  \n",
       "29              2937500.0  \n",
       "30              2937500.0  \n",
       "31              2937500.0  \n",
       "32              2937500.0  \n",
       "33              2750800.0  \n",
       "34              2701750.0  \n",
       "35              2701750.0  \n",
       "36              2559150.0  \n",
       "37              2431650.0  \n",
       "38              2294150.0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_parquet('../data/featuresAdded_stocks_etfs/A.parquet').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work_sample",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
