{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, IntegerType\n",
    "from pyspark.sql.functions import input_file_name, lit, col, isnull\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/28 22:22:22 WARN Utils: Your hostname, Hops-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.0.140 instead (on interface en0)\n",
      "23/07/28 22:22:22 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/07/28 22:22:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "#Create a spark Context class, with custom config\n",
    "conf = SparkConf()\n",
    "conf.set('spark.default.parallelism', 700)\n",
    "conf.set('spark.sql.shuffle.partitions', 700)\n",
    "conf.set('spark.driver.memory', '30g')\n",
    "conf.set('spark.driver.cores', 8)\n",
    "conf.set('spark.executor.cores', 8)\n",
    "conf.set('spark.executor.memory', '30g')\n",
    "sc = SparkContext.getOrCreate(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create spark session\n",
    "spark = SparkSession.builder.master('local[*]').\\\n",
    "                config('spark.sql.debug.maxToStringFields', '100').\\\n",
    "                appName(\"ETFs Spark Airflow Docker\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "existing_schema = StructType([\n",
    "    StructField(\"Date\", StringType(), False),\n",
    "    StructField(\"Open\", FloatType(), False),\n",
    "    StructField(\"High\", FloatType(), False),\n",
    "    StructField(\"Low\", FloatType(), False),\n",
    "    StructField(\"Close\", FloatType(), False),\n",
    "    StructField(\"Adj Close\", FloatType(), False),\n",
    "    StructField(\"Volume\", FloatType(), False),\n",
    "    StructField(\"Symbol\", FloatType(), False),\n",
    "    StructField(\"Security Name\", FloatType(), False)\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"../data/stocks_etfs/A.csv\"\n",
    "stock_df = spark.read.csv(input_path, header=True, schema=existing_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Open: float (nullable = true)\n",
      " |-- High: float (nullable = true)\n",
      " |-- Low: float (nullable = true)\n",
      " |-- Close: float (nullable = true)\n",
      " |-- Adj Close: float (nullable = true)\n",
      " |-- Volume: float (nullable = true)\n",
      " |-- Symbol: float (nullable = true)\n",
      " |-- Security Name: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stock_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_symbol = spark.read.csv(\"../data/symbols_valid_meta.csv\", header=True)\n",
    "symbol_mapping = meta_symbol.select(\"Symbol\", \"Security Name\").rdd.collectAsMap()\n",
    "symbol_name = os.path.splitext(os.path.basename(input_path))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+---------+---------+---------+---------+------+-------------+\n",
      "|      Date|     Open|     High|      Low|    Close|Adj Close|   Volume|Symbol|Security Name|\n",
      "+----------+---------+---------+---------+---------+---------+---------+------+-------------+\n",
      "|1999-11-18|32.546494| 35.76538|28.612303|31.473534|27.068665|6.25463E7|  null|         null|\n",
      "|1999-11-19| 30.71352|30.758226|28.478184|28.880543|24.838577|1.52341E7|  null|         null|\n",
      "|1999-11-22|29.551144|31.473534| 28.65701|31.473534|27.068665|6577800.0|  null|         null|\n",
      "|1999-11-23|30.400572|31.205294|28.612303|28.612303| 24.60788|5975600.0|  null|         null|\n",
      "|1999-11-24|28.701717| 29.99821|28.612303|29.372318|25.261524|4843200.0|  null|         null|\n",
      "|1999-11-26|29.238197|29.685265|29.148785|29.461731|25.338428|1729400.0|  null|         null|\n",
      "|1999-11-29| 29.32761|30.355865|29.014664|30.132332|25.915169|4074700.0|  null|         null|\n",
      "|1999-11-30| 30.04292| 30.71352|29.282904|30.177038|25.953619|4310000.0|  null|         null|\n",
      "|1999-12-01|30.177038|31.071173|29.953505| 30.71352|26.415012|2957300.0|  null|         null|\n",
      "|1999-12-02|31.294706|32.188843|30.892345|31.562946|27.145563|3069800.0|  null|         null|\n",
      "+----------+---------+---------+---------+---------+---------+---------+------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/26 01:25:58 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 7, schema size: 9\n",
      "CSV file: file:///Users/hople/working_folder/Bootcamp_practices/ML_PIPELINE_AIRFLOW_SPARK_DOCKER/Dockerize_entire_workflow/dags/data/stocks_etfs/A.csv\n"
     ]
    }
   ],
   "source": [
    "stock_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_df = stock_df.withColumn(\"Symbol\", F.lit(symbol_name))\n",
    "stock_df = stock_df.withColumn(\"Security Name\", F.lit(symbol_mapping.get(symbol_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_df.write.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+---------+---------+---------+---------+------+--------------------+\n",
      "|      Date|     Open|     High|      Low|    Close|Adj Close|   Volume|Symbol|       Security Name|\n",
      "+----------+---------+---------+---------+---------+---------+---------+------+--------------------+\n",
      "|1999-11-18|32.546494| 35.76538|28.612303|31.473534|27.068665|6.25463E7|     A|Agilent Technolog...|\n",
      "|1999-11-19| 30.71352|30.758226|28.478184|28.880543|24.838577|1.52341E7|     A|Agilent Technolog...|\n",
      "|1999-11-22|29.551144|31.473534| 28.65701|31.473534|27.068665|6577800.0|     A|Agilent Technolog...|\n",
      "|1999-11-23|30.400572|31.205294|28.612303|28.612303| 24.60788|5975600.0|     A|Agilent Technolog...|\n",
      "|1999-11-24|28.701717| 29.99821|28.612303|29.372318|25.261524|4843200.0|     A|Agilent Technolog...|\n",
      "|1999-11-26|29.238197|29.685265|29.148785|29.461731|25.338428|1729400.0|     A|Agilent Technolog...|\n",
      "|1999-11-29| 29.32761|30.355865|29.014664|30.132332|25.915169|4074700.0|     A|Agilent Technolog...|\n",
      "|1999-11-30| 30.04292| 30.71352|29.282904|30.177038|25.953619|4310000.0|     A|Agilent Technolog...|\n",
      "|1999-12-01|30.177038|31.071173|29.953505| 30.71352|26.415012|2957300.0|     A|Agilent Technolog...|\n",
      "|1999-12-02|31.294706|32.188843|30.892345|31.562946|27.145563|3069800.0|     A|Agilent Technolog...|\n",
      "+----------+---------+---------+---------+---------+---------+---------+------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stock_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Security Name: string]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_df.select(\"Security Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Open: float (nullable = true)\n",
      " |-- High: float (nullable = true)\n",
      " |-- Low: float (nullable = true)\n",
      " |-- Close: float (nullable = true)\n",
      " |-- Adj Close: float (nullable = true)\n",
      " |-- Volume: float (nullable = true)\n",
      " |-- Symbol: string (nullable = false)\n",
      " |-- Security Name: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stock_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from save_parquet import save_parquet\n",
    "import os\n",
    "\n",
    "#retain features columns\n",
    "features = ['Symbol', 'Security Name', 'Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
    "#path to save processed dataset\n",
    "path = '../data/processed_stocks_etfs/'\n",
    "#read metal symbol files\n",
    "metal_symbol = pd.read_csv('../data/symbols_valid_meta.csv')\n",
    "metal_symbol = metal_symbol[['Symbol', 'Security Name']]\n",
    "#correct some wrong spelling, coresponding to Stock file name\n",
    "metal_symbol['Symbol'] = metal_symbol['Symbol'].str.replace('$', '-',regex=False)\n",
    "metal_symbol['Symbol'] = metal_symbol['Symbol'].str.replace('.V', '',regex=False)\n",
    "#creat mapping dictionary\n",
    "symbol_mapping = metal_symbol.set_index('Symbol').to_dict()['Security Name']\n",
    "\n",
    "def add_name(file):\n",
    "    #print(symbol_mapping)\n",
    "    name = os.path.splitext(os.path.basename(file))[0]\n",
    "    df = pd.read_csv(file)\n",
    "    df['Symbol'] = name\n",
    "    sec_name = symbol_mapping[name]\n",
    "    df['Security Name'] = sec_name\n",
    "    #print(sec_name)\n",
    "    #df.name = name\n",
    "    #return df\n",
    "    save_parquet(df[features], name, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count\n",
    "\n",
    "stocks_path = '../data/stocks_etfs/'\n",
    "#path = '../data/processed_stocks_etfs/'\n",
    "from load_files import load_file\n",
    "#list of loaded csv files will split into n_processor, for parralezation process\n",
    "n_processor = cpu_count()\n",
    "#get batches of data, list of list\n",
    "preprocessing_list = load_file(n_processor, stocks_path, 'csv')\n",
    "\n",
    "\n",
    "def data_processing():\n",
    "    '''\n",
    "    Takes batch number as input\n",
    "    Map function add_name for every dataframe in batch number in preprocessing_list\n",
    "    '''\n",
    "    temp = list(map(add_name, preprocessing_list))\n",
    "\n",
    "#data_processing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/07/28 01:06:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql import functions as F\n",
    "import os\n",
    "from multiprocessing import cpu_count\n",
    "from load_files import load_file #function load files into batches\n",
    "\n",
    "#Create a spark Context class, with custom config to optimize the performance\n",
    "#conf.set('spark.sql.adaptive.coalescePartitions.initialPartitionNum', 24)\n",
    "#conf.set('spark.sql.adaptive.coalescePartitions.parallelismFirst', 'false')\n",
    "#conf.set('spark.sql.files.minPartitionNum', 1)\n",
    "conf = SparkConf()\n",
    "conf.set('spark.default.parallelism', 700)\n",
    "conf.set('spark.sql.shuffle.partitions', 700)\n",
    "#conf.set('spark.sql.files.maxPartitionBytes', '500mb')\n",
    "conf.set('spark.driver.memory', '30g')\n",
    "conf.set('spark.driver.cores', 8)\n",
    "conf.set('spark.executor.cores', 8)\n",
    "conf.set('spark.executor.memory', '30g')\n",
    "sc = SparkContext.getOrCreate(conf)\n",
    "\n",
    "## Initialize SparkSession\n",
    "spark = SparkSession.builder.master('local[*]').\\\n",
    "                config('spark.sql.debug.maxToStringFields', '100').\\\n",
    "                appName(\"ETFs Spark Airflow Docker\").getOrCreate()\n",
    "\n",
    "\n",
    "#stock dir\n",
    "stocks_dir = \"../data/stocks_etfs\"\n",
    "#processed data dir\n",
    "processed_stocks_dir = \"../data/processed_stocks_etfs\"\n",
    "\n",
    "#Mapping dict\n",
    "meta_symbol = spark.read.csv(\"../data/symbols_valid_meta.csv\", header=True)\n",
    "symbol_mapping = meta_symbol.select(\"Symbol\", \"Security Name\").rdd.collectAsMap()\n",
    "\n",
    "#Define Schema for the data\n",
    "existing_schema = StructType([\n",
    "    StructField(\"Date\", StringType(), False),\n",
    "    StructField(\"Open\", FloatType(), False),\n",
    "    StructField(\"High\", FloatType(), False),\n",
    "    StructField(\"Low\", FloatType(), False),\n",
    "    StructField(\"Close\", FloatType(), False),\n",
    "    StructField(\"Adj Close\", FloatType(), False),\n",
    "    StructField(\"Volume\", FloatType(), False),\n",
    "    StructField(\"Symbol\", FloatType(), False),\n",
    "    StructField(\"Security Name\", FloatType(), False)\n",
    "\n",
    "])\n",
    "\n",
    "def add_sym_sec_name(input_file):\n",
    "    \"\"\"\n",
    "    Function adds Symbol and Security Name to stock file\n",
    "    \"\"\"\n",
    "    # Read data from CSV into the DataFrame using the existing schema\n",
    "    stock_df = spark.read.csv(input_file, header=True, schema=existing_schema)\n",
    "\n",
    "    # Get Symbol name from input file\n",
    "    symbol_name = os.path.splitext(os.path.basename(input_file))[0]\n",
    "\n",
    "    # Adding Symbol and Security Name\n",
    "    stock_df = stock_df.withColumn(\"Symbol\", F.lit(symbol_name))\n",
    "    stock_df = stock_df.withColumn(\"Security Name\", F.lit(symbol_mapping.get(symbol_name)))\n",
    "\n",
    "    # Save the preprocessed data to a parquet file\n",
    "    #output_file = os.path.join(processed_stocks_dir, f\"{symbol_name}_preprocessed.parquet\")\n",
    "    output_file = f\"{processed_stocks_dir}/{symbol_name}_preprocessed.parquet\"\n",
    "    stock_df.write.parquet(output_file, mode=\"overwrite\")\n",
    "\n",
    "\n",
    "def preprocessing_data():\n",
    "    '''\n",
    "    Takes batch number as input\n",
    "    Map function add_sym_sec_name for every dataframe in batch number in preprocessing_list\n",
    "    '''\n",
    "    #list of loaded csv files will split into n_processor, for parralezation process in Airflow\n",
    "    n_processor = cpu_count()\n",
    "    #get batches of data\n",
    "    preprocessing_list = load_file(n_processor, stocks_dir, 'csv')\n",
    "    #temp = list(map(add_sym_sec_name, ('../data/stocks_etfs/A.csv')))\n",
    "    #print(preprocessing_list)\n",
    "\n",
    "preprocessing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessing_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mstr\u001b[39m(preprocessing_list[\u001b[39m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocessing_list' is not defined"
     ]
    }
   ],
   "source": [
    "str(preprocessing_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+----------+----------+----------+--------+------+-------------+\n",
      "|      Date|      Open|      High|       Low|     Close| Adj Close|  Volume|Symbol|Security Name|\n",
      "+----------+----------+----------+----------+----------+----------+--------+------+-------------+\n",
      "|1988-02-04|       0.0|0.61728394| 0.5555556| 0.5555556|0.42403868| 38700.0|  null|         null|\n",
      "|1988-02-05|       0.0|0.61728394| 0.5555556| 0.5555556|0.42403868|606300.0|  null|         null|\n",
      "|1988-02-08|       0.0|0.61728394| 0.5555556| 0.5555556|0.42403868| 19000.0|  null|         null|\n",
      "|1988-02-09|       0.0|0.61728394| 0.5555556| 0.5555556|0.42403868| 23100.0|  null|         null|\n",
      "|1988-02-10|       0.0|0.61728394| 0.5555556| 0.5555556|0.42403868| 10000.0|  null|         null|\n",
      "|1988-02-11|       0.0|0.61728394| 0.5555556| 0.5555556|0.42403868| 10900.0|  null|         null|\n",
      "|1988-02-12|       0.0|0.61728394| 0.5555556| 0.5555556|0.42403868|     0.0|  null|         null|\n",
      "|1988-02-16|       0.0|0.61728394|0.52469134|0.52469134|0.40048075| 66700.0|  null|         null|\n",
      "|1988-02-17|0.52469134|0.52469134|0.52469134|0.52469134|0.40048075|     0.0|  null|         null|\n",
      "|1988-02-18|       0.0|0.61728394|0.49382716|0.49382716| 0.3769232| 21100.0|  null|         null|\n",
      "+----------+----------+----------+----------+----------+----------+--------+------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/28 00:37:48 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 7, schema size: 9\n",
      "CSV file: file:///Users/hople/working_folder/ML_PIPELINE_AIRFLOW_SPARK_DOCKER/dags/data/stocks_etfs/IPAR.csv\n"
     ]
    }
   ],
   "source": [
    "spark.read.csv(str(preprocessing_list[0]), header=True, schema=existing_schema).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AAL_preprocessed'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from load_files import load_file\n",
    "from multiprocessing import cpu_count\n",
    "stocks_dir = '../data/stocks_etfs/'\n",
    "n_processor = cpu_count()\n",
    "#get batches of data\n",
    "preprocessing_list = load_file(n_processor, '../data/processed_stocks_etfs/', 'parquet')\n",
    "\n",
    "preprocessing_list[0][0].stem\n",
    "#pd.read_parquet(preprocessing_list[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/01 19:12:26 WARN Utils: Your hostname, Hops-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.0.140 instead (on interface en0)\n",
      "23/08/01 19:12:26 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/08/01 19:12:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from sparksession import initilize_sparksession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, DateType\n",
    "from pyspark.sql import functions as F\n",
    "spark = initilize_sparksession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "processed_stock = spark.read.parquet('../data/processed_stocks_etfs/A_preprocessed.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Symbol: string (nullable = true)\n",
      " |-- Security Name: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Open: float (nullable = true)\n",
      " |-- High: float (nullable = true)\n",
      " |-- Low: float (nullable = true)\n",
      " |-- Close: float (nullable = true)\n",
      " |-- Adj Close: float (nullable = true)\n",
      " |-- Volume: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processed_stock.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+----------+---------+---------+---------+---------+---------+---------+\n",
      "|Symbol|       Security Name|      Date|     Open|     High|      Low|    Close|Adj Close|   Volume|\n",
      "+------+--------------------+----------+---------+---------+---------+---------+---------+---------+\n",
      "|     A|Agilent Technolog...|1999-11-18|32.546494| 35.76538|28.612303|31.473534|27.068665|6.25463E7|\n",
      "|     A|Agilent Technolog...|1999-11-19| 30.71352|30.758226|28.478184|28.880543|24.838577|1.52341E7|\n",
      "|     A|Agilent Technolog...|1999-11-22|29.551144|31.473534| 28.65701|31.473534|27.068665|6577800.0|\n",
      "|     A|Agilent Technolog...|1999-11-23|30.400572|31.205294|28.612303|28.612303| 24.60788|5975600.0|\n",
      "|     A|Agilent Technolog...|1999-11-24|28.701717| 29.99821|28.612303|29.372318|25.261524|4843200.0|\n",
      "|     A|Agilent Technolog...|1999-11-26|29.238197|29.685265|29.148785|29.461731|25.338428|1729400.0|\n",
      "|     A|Agilent Technolog...|1999-11-29| 29.32761|30.355865|29.014664|30.132332|25.915169|4074700.0|\n",
      "|     A|Agilent Technolog...|1999-11-30| 30.04292| 30.71352|29.282904|30.177038|25.953619|4310000.0|\n",
      "|     A|Agilent Technolog...|1999-12-01|30.177038|31.071173|29.953505| 30.71352|26.415012|2957300.0|\n",
      "|     A|Agilent Technolog...|1999-12-02|31.294706|32.188843|30.892345|31.562946|27.145563|3069800.0|\n",
      "+------+--------------------+----------+---------+---------+---------+---------+---------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processed_stock.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate volume moving average using Window function for the last 30 days, including the current row\n",
    "w_date = Window.partitionBy(F.lit(0)).orderBy(F.col('Date')).rowsBetween(-29, 0)\n",
    "processed_stock = processed_stock.withColumn('vol_moving_avg', F.mean('Volume').over(w_date))\n",
    "processed_stock = processed_stock.withColumn('vol_moving_avg', F.round('vol_moving_avg', 0))\n",
    "# Calculate the rolling median for the 'Volume' column over the last 30 days\n",
    "processed_stock = processed_stock.withColumn('adj_close_rolling_med', F.expr('percentile(Volume, 0.5)').over(w_date))\n",
    "processed_stock = processed_stock.withColumn('adj_close_rolling_med', F.round('adj_close_rolling_med', 0))\n",
    "#drop the first 30 days\n",
    "featured_stock = processed_stock.withColumn(\"counter\", F.monotonically_increasing_id())\n",
    "w_counter = Window.partitionBy(F.lit(0)).orderBy(\"counter\")\n",
    "featured_stock = featured_stock.withColumn(\"index\", F.row_number().over(w_counter))\n",
    "featured_stock = featured_stock.filter(F.col(\"index\") >= 30)\n",
    "featured_stock = featured_stock.drop(\"counter\", \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Project [Symbol#0, Security Name#1, Date#2, Open#3, High#4, Low#5, Close#6, Adj Close#7, Volume#8, round(vol_moving_avg#57, 0) AS vol_moving_avg#68, round(adj_close_rolling_med#79, 0) AS adj_close_rolling_med#92]\n",
      "   +- Window [avg(Volume#8) windowspecdefinition(0, Date#2 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -29, currentrow$())) AS vol_moving_avg#57, percentile(Volume#8, 0.5, 1, 0, 0, false) windowspecdefinition(0, Date#2 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -29, currentrow$())) AS adj_close_rolling_med#79], [0], [Date#2 ASC NULLS FIRST]\n",
      "      +- Sort [0 ASC NULLS FIRST, Date#2 ASC NULLS FIRST], false, 0\n",
      "         +- Exchange hashpartitioning(0, 8), ENSURE_REQUIREMENTS, [plan_id=28]\n",
      "            +- FileScan parquet [Symbol#0,Security Name#1,Date#2,Open#3,High#4,Low#5,Close#6,Adj Close#7,Volume#8] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/Users/hople/working_folder/ML_PIPELINE_AIRFLOW_SPARK_DOCKER/dags..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Symbol:string,Security Name:string,Date:string,Open:float,High:float,Low:float,Close:float...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processed_stock.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+----------+---------+---------+---------+---------+---------+---------+--------------+---------------------+\n",
      "|Symbol|       Security Name|      Date|     Open|     High|      Low|    Close|Adj Close|   Volume|vol_moving_avg|adj_close_rolling_med|\n",
      "+------+--------------------+----------+---------+---------+---------+---------+---------+---------+--------------+---------------------+\n",
      "|     A|Agilent Technolog...|1999-12-31| 56.86695|  57.1799|54.542202|55.302216|47.562416|1931100.0|     5739950.0|            2937500.0|\n",
      "|     A|Agilent Technolog...|2000-01-03| 56.33047|56.464592|48.193848|51.502148| 44.29417|4674300.0|     3810883.0|            2937500.0|\n",
      "|     A|Agilent Technolog...|2000-01-04|48.730328| 49.26681|46.316166|47.567955| 40.91059|4765000.0|     3461913.0|            2937500.0|\n",
      "|     A|Agilent Technolog...|2000-01-05|47.389126|47.567955|43.141987| 44.61731|38.372894|5758600.0|     3434607.0|            2937500.0|\n",
      "|     A|Agilent Technolog...|2000-01-06| 44.08083| 44.34907| 41.57725|42.918453|36.911816|2534400.0|     3319900.0|            2750800.0|\n",
      "|     A|Agilent Technolog...|2000-01-07|42.247852|47.165592|42.203148| 46.49499|39.987797|2819600.0|     3252447.0|            2701750.0|\n",
      "|     A|Agilent Technolog...|2000-01-10|49.356224| 49.80329| 48.32797|49.311516|42.410137|2148400.0|     3266413.0|            2701750.0|\n",
      "|     A|Agilent Technolog...|2000-01-11|49.311516|49.311516|47.523247|48.640915|41.833397|1855900.0|     3192453.0|            2559150.0|\n",
      "|     A|Agilent Technolog...|2000-01-12|48.640915|48.640915| 45.82439|47.657368|40.987488|1429800.0|     3096447.0|            2431650.0|\n",
      "|     A|Agilent Technolog...|2000-01-13|48.909157|49.937412|  47.2103|48.372677|41.602703|1134300.0|     3035680.0|            2294150.0|\n",
      "+------+--------------------+----------+---------+---------+---------+---------+---------+---------+--------------+---------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featured_stock.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Security Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>vol_moving_avg</th>\n",
       "      <th>adj_close_rolling_med</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-02-11</td>\n",
       "      <td>54.721031</td>\n",
       "      <td>54.944565</td>\n",
       "      <td>53.513950</td>\n",
       "      <td>53.916309</td>\n",
       "      <td>46.370472</td>\n",
       "      <td>751700.0</td>\n",
       "      <td>1951013.0</td>\n",
       "      <td>1694350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-02-14</td>\n",
       "      <td>53.826897</td>\n",
       "      <td>55.033978</td>\n",
       "      <td>53.513950</td>\n",
       "      <td>54.676323</td>\n",
       "      <td>47.024109</td>\n",
       "      <td>837600.0</td>\n",
       "      <td>1914563.0</td>\n",
       "      <td>1519500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-02-15</td>\n",
       "      <td>54.765736</td>\n",
       "      <td>59.370529</td>\n",
       "      <td>54.765736</td>\n",
       "      <td>58.565807</td>\n",
       "      <td>50.369244</td>\n",
       "      <td>2017500.0</td>\n",
       "      <td>1826003.0</td>\n",
       "      <td>1519500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-02-16</td>\n",
       "      <td>57.224606</td>\n",
       "      <td>58.565807</td>\n",
       "      <td>56.777538</td>\n",
       "      <td>57.939915</td>\n",
       "      <td>49.830936</td>\n",
       "      <td>1801700.0</td>\n",
       "      <td>1727227.0</td>\n",
       "      <td>1519500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-02-17</td>\n",
       "      <td>57.939915</td>\n",
       "      <td>69.384834</td>\n",
       "      <td>55.525749</td>\n",
       "      <td>69.384834</td>\n",
       "      <td>59.674088</td>\n",
       "      <td>944900.0</td>\n",
       "      <td>1566770.0</td>\n",
       "      <td>1417000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-02-18</td>\n",
       "      <td>63.304722</td>\n",
       "      <td>68.580116</td>\n",
       "      <td>62.991776</td>\n",
       "      <td>67.060089</td>\n",
       "      <td>57.674717</td>\n",
       "      <td>4060000.0</td>\n",
       "      <td>1617623.0</td>\n",
       "      <td>1417000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-02-22</td>\n",
       "      <td>68.669525</td>\n",
       "      <td>69.653076</td>\n",
       "      <td>64.377686</td>\n",
       "      <td>65.450645</td>\n",
       "      <td>56.290516</td>\n",
       "      <td>2227900.0</td>\n",
       "      <td>1597900.0</td>\n",
       "      <td>1417000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-02-23</td>\n",
       "      <td>65.540054</td>\n",
       "      <td>71.888412</td>\n",
       "      <td>65.540054</td>\n",
       "      <td>70.815453</td>\n",
       "      <td>60.904503</td>\n",
       "      <td>1690000.0</td>\n",
       "      <td>1582620.0</td>\n",
       "      <td>1417000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-02-24</td>\n",
       "      <td>72.514305</td>\n",
       "      <td>82.573318</td>\n",
       "      <td>71.888412</td>\n",
       "      <td>76.359085</td>\n",
       "      <td>65.672264</td>\n",
       "      <td>2956300.0</td>\n",
       "      <td>1619300.0</td>\n",
       "      <td>1417000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-02-25</td>\n",
       "      <td>73.944923</td>\n",
       "      <td>81.500359</td>\n",
       "      <td>73.855507</td>\n",
       "      <td>77.342636</td>\n",
       "      <td>66.518181</td>\n",
       "      <td>2048200.0</td>\n",
       "      <td>1639913.0</td>\n",
       "      <td>1506700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-02-28</td>\n",
       "      <td>77.342636</td>\n",
       "      <td>78.102646</td>\n",
       "      <td>70.278969</td>\n",
       "      <td>72.246063</td>\n",
       "      <td>62.134861</td>\n",
       "      <td>1675300.0</td>\n",
       "      <td>1657947.0</td>\n",
       "      <td>1642250.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Symbol                            Security Name        Date       Open  \\\n",
       "29      A  Agilent Technologies, Inc. Common Stock  2000-02-11  54.721031   \n",
       "30      A  Agilent Technologies, Inc. Common Stock  2000-02-14  53.826897   \n",
       "31      A  Agilent Technologies, Inc. Common Stock  2000-02-15  54.765736   \n",
       "32      A  Agilent Technologies, Inc. Common Stock  2000-02-16  57.224606   \n",
       "33      A  Agilent Technologies, Inc. Common Stock  2000-02-17  57.939915   \n",
       "34      A  Agilent Technologies, Inc. Common Stock  2000-02-18  63.304722   \n",
       "35      A  Agilent Technologies, Inc. Common Stock  2000-02-22  68.669525   \n",
       "36      A  Agilent Technologies, Inc. Common Stock  2000-02-23  65.540054   \n",
       "37      A  Agilent Technologies, Inc. Common Stock  2000-02-24  72.514305   \n",
       "38      A  Agilent Technologies, Inc. Common Stock  2000-02-25  73.944923   \n",
       "39      A  Agilent Technologies, Inc. Common Stock  2000-02-28  77.342636   \n",
       "\n",
       "         High        Low      Close  Adj Close     Volume  vol_moving_avg  \\\n",
       "29  54.944565  53.513950  53.916309  46.370472   751700.0       1951013.0   \n",
       "30  55.033978  53.513950  54.676323  47.024109   837600.0       1914563.0   \n",
       "31  59.370529  54.765736  58.565807  50.369244  2017500.0       1826003.0   \n",
       "32  58.565807  56.777538  57.939915  49.830936  1801700.0       1727227.0   \n",
       "33  69.384834  55.525749  69.384834  59.674088   944900.0       1566770.0   \n",
       "34  68.580116  62.991776  67.060089  57.674717  4060000.0       1617623.0   \n",
       "35  69.653076  64.377686  65.450645  56.290516  2227900.0       1597900.0   \n",
       "36  71.888412  65.540054  70.815453  60.904503  1690000.0       1582620.0   \n",
       "37  82.573318  71.888412  76.359085  65.672264  2956300.0       1619300.0   \n",
       "38  81.500359  73.855507  77.342636  66.518181  2048200.0       1639913.0   \n",
       "39  78.102646  70.278969  72.246063  62.134861  1675300.0       1657947.0   \n",
       "\n",
       "    adj_close_rolling_med  \n",
       "29              1694350.0  \n",
       "30              1519500.0  \n",
       "31              1519500.0  \n",
       "32              1519500.0  \n",
       "33              1417000.0  \n",
       "34              1417000.0  \n",
       "35              1417000.0  \n",
       "36              1417000.0  \n",
       "37              1417000.0  \n",
       "38              1506700.0  \n",
       "39              1642250.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featured_stock.limit(40).toPandas().iloc[29:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Security Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>vol_moving_avg</th>\n",
       "      <th>adj_close_rolling_med</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>56.866951</td>\n",
       "      <td>57.179901</td>\n",
       "      <td>54.542202</td>\n",
       "      <td>55.302216</td>\n",
       "      <td>47.562416</td>\n",
       "      <td>1931100</td>\n",
       "      <td>5.739950e+06</td>\n",
       "      <td>2937500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>56.330471</td>\n",
       "      <td>56.464592</td>\n",
       "      <td>48.193848</td>\n",
       "      <td>51.502148</td>\n",
       "      <td>44.294170</td>\n",
       "      <td>4674300</td>\n",
       "      <td>3.810883e+06</td>\n",
       "      <td>2937500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>48.730328</td>\n",
       "      <td>49.266811</td>\n",
       "      <td>46.316166</td>\n",
       "      <td>47.567955</td>\n",
       "      <td>40.910591</td>\n",
       "      <td>4765000</td>\n",
       "      <td>3.461913e+06</td>\n",
       "      <td>2937500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>47.389126</td>\n",
       "      <td>47.567955</td>\n",
       "      <td>43.141987</td>\n",
       "      <td>44.617310</td>\n",
       "      <td>38.372894</td>\n",
       "      <td>5758600</td>\n",
       "      <td>3.434607e+06</td>\n",
       "      <td>2937500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>44.080830</td>\n",
       "      <td>44.349072</td>\n",
       "      <td>41.577251</td>\n",
       "      <td>42.918453</td>\n",
       "      <td>36.911816</td>\n",
       "      <td>2534400</td>\n",
       "      <td>3.319900e+06</td>\n",
       "      <td>2750800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>42.247852</td>\n",
       "      <td>47.165592</td>\n",
       "      <td>42.203148</td>\n",
       "      <td>46.494991</td>\n",
       "      <td>39.987797</td>\n",
       "      <td>2819600</td>\n",
       "      <td>3.252447e+06</td>\n",
       "      <td>2701750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-01-10</td>\n",
       "      <td>49.356224</td>\n",
       "      <td>49.803291</td>\n",
       "      <td>48.327969</td>\n",
       "      <td>49.311516</td>\n",
       "      <td>42.410137</td>\n",
       "      <td>2148400</td>\n",
       "      <td>3.266413e+06</td>\n",
       "      <td>2701750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-01-11</td>\n",
       "      <td>49.311516</td>\n",
       "      <td>49.311516</td>\n",
       "      <td>47.523247</td>\n",
       "      <td>48.640915</td>\n",
       "      <td>41.833397</td>\n",
       "      <td>1855900</td>\n",
       "      <td>3.192453e+06</td>\n",
       "      <td>2559150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-01-12</td>\n",
       "      <td>48.640915</td>\n",
       "      <td>48.640915</td>\n",
       "      <td>45.824390</td>\n",
       "      <td>47.657368</td>\n",
       "      <td>40.987488</td>\n",
       "      <td>1429800</td>\n",
       "      <td>3.096447e+06</td>\n",
       "      <td>2431650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc. Common Stock</td>\n",
       "      <td>2000-01-13</td>\n",
       "      <td>48.909157</td>\n",
       "      <td>49.937412</td>\n",
       "      <td>47.210300</td>\n",
       "      <td>48.372677</td>\n",
       "      <td>41.602703</td>\n",
       "      <td>1134300</td>\n",
       "      <td>3.035680e+06</td>\n",
       "      <td>2294150.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Symbol                            Security Name       Date       Open  \\\n",
       "29      A  Agilent Technologies, Inc. Common Stock 1999-12-31  56.866951   \n",
       "30      A  Agilent Technologies, Inc. Common Stock 2000-01-03  56.330471   \n",
       "31      A  Agilent Technologies, Inc. Common Stock 2000-01-04  48.730328   \n",
       "32      A  Agilent Technologies, Inc. Common Stock 2000-01-05  47.389126   \n",
       "33      A  Agilent Technologies, Inc. Common Stock 2000-01-06  44.080830   \n",
       "34      A  Agilent Technologies, Inc. Common Stock 2000-01-07  42.247852   \n",
       "35      A  Agilent Technologies, Inc. Common Stock 2000-01-10  49.356224   \n",
       "36      A  Agilent Technologies, Inc. Common Stock 2000-01-11  49.311516   \n",
       "37      A  Agilent Technologies, Inc. Common Stock 2000-01-12  48.640915   \n",
       "38      A  Agilent Technologies, Inc. Common Stock 2000-01-13  48.909157   \n",
       "\n",
       "         High        Low      Close  Adj Close   Volume  vol_moving_avg  \\\n",
       "29  57.179901  54.542202  55.302216  47.562416  1931100    5.739950e+06   \n",
       "30  56.464592  48.193848  51.502148  44.294170  4674300    3.810883e+06   \n",
       "31  49.266811  46.316166  47.567955  40.910591  4765000    3.461913e+06   \n",
       "32  47.567955  43.141987  44.617310  38.372894  5758600    3.434607e+06   \n",
       "33  44.349072  41.577251  42.918453  36.911816  2534400    3.319900e+06   \n",
       "34  47.165592  42.203148  46.494991  39.987797  2819600    3.252447e+06   \n",
       "35  49.803291  48.327969  49.311516  42.410137  2148400    3.266413e+06   \n",
       "36  49.311516  47.523247  48.640915  41.833397  1855900    3.192453e+06   \n",
       "37  48.640915  45.824390  47.657368  40.987488  1429800    3.096447e+06   \n",
       "38  49.937412  47.210300  48.372677  41.602703  1134300    3.035680e+06   \n",
       "\n",
       "    adj_close_rolling_med  \n",
       "29              2937500.0  \n",
       "30              2937500.0  \n",
       "31              2937500.0  \n",
       "32              2937500.0  \n",
       "33              2750800.0  \n",
       "34              2701750.0  \n",
       "35              2701750.0  \n",
       "36              2559150.0  \n",
       "37              2431650.0  \n",
       "38              2294150.0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_parquet('../data/featuresAdded_stocks_etfs/A.parquet').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "def calculate_volume_moving_average_and_median(df):\n",
    "    # Calculate volume moving average using Window function for the last 30 days, including the current row\n",
    "    window_spec = Window.orderBy(F.col('Date')).rowsBetween(-29, 0)\n",
    "    df = df.withColumn('vol_moving_avg', F.avg('Volume').over(window_spec))\n",
    "\n",
    "    # Calculate the rolling median for the 'Volume' column over the last 30 days\n",
    "    w_date = Window.orderBy(F.col('Date')).rowsBetween(-29, 0)\n",
    "    df = df.withColumn('vol_rolling_median', F.expr('percentile_approx(Volume, 0.5) OVER w_date'))\n",
    "\n",
    "    return df\n",
    "\n",
    "class TestVolumeMovingAverageAndMedian(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        self.spark = SparkSession.builder.appName(\"TestVolumeMovingAverageAndMedian\").getOrCreate()\n",
    "\n",
    "    def tearDown(self):\n",
    "        self.spark.stop()\n",
    "\n",
    "    def test_calculate_volume_moving_average_and_median(self):\n",
    "        # Create a test DataFrame with 'Date' and 'Volume' columns\n",
    "        data = [\n",
    "            (\"2023-07-01\", 100),\n",
    "            (\"2023-07-02\", 150),\n",
    "            (\"2023-07-03\", 200),\n",
    "            # Add more test data here...\n",
    "        ]\n",
    "        schema = [\"Date\", \"Volume\"]\n",
    "        df = self.spark.createDataFrame(data, schema)\n",
    "\n",
    "        # Calculate the volume moving average and rolling median using the function being tested\n",
    "        result_df = calculate_volume_moving_average_and_median(df)\n",
    "\n",
    "        # Assert the correctness of the results\n",
    "        # You can add more specific assertions based on your expected results.\n",
    "        # For example, if you know the expected values for certain dates, you can use assert statements to check them.\n",
    "        self.assertTrue(\"vol_moving_avg\" in result_df.columns)\n",
    "        self.assertTrue(\"vol_rolling_median\" in result_df.columns)\n",
    "        self.assertEqual(result_df.count(), df.count())  # Ensure no rows are lost during processing\n",
    "        self.assertGreater(result_df.filter(F.col(\"vol_moving_avg\").isNull()).count(), 0)  # Check for null values in the moving average column\n",
    "        self.assertGreater(result_df.filter(F.col(\"vol_rolling_median\").isNull()).count(), 0)  # Check for null values in the rolling median column\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processed data dir\n",
    "processed_stocks_dir = \"../data/processed_stocks_etfs/\"\n",
    "#featured data dir\n",
    "featured_stocks_dir = '../data/featuresAdded_stocks_etfs/'\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "from load_files import load_file\n",
    "#list of loaded csv files will split into n_processor batches, for parralezation data processing in Airflow\n",
    "n_processor = cpu_count()\n",
    "#get batches of data\n",
    "preprocessing_list = load_file(n_processor, processed_stocks_dir, 'parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../data/processed_stocks_etfs/AAL_preprocessed.parquet')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_list[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+-------------------+------------------+------------------+------------------+------------------+------------------+-------+------------------+---------------------+-----------------+\n",
      "|Symbol|       Security Name|               Date|              Open|              High|               Low|             Close|         Adj Close| Volume|    vol_moving_avg|adj_close_rolling_med|__index_level_0__|\n",
      "+------+--------------------+-------------------+------------------+------------------+------------------+------------------+------------------+-------+------------------+---------------------+-----------------+\n",
      "|     A|Agilent Technolog...|1999-12-31 00:00:00| 56.86695098876953|57.179901123046875| 54.54220199584961|55.302215576171875| 47.56241607666016|1931100|         5739950.0|            2937500.0|               29|\n",
      "|     A|Agilent Technolog...|2000-01-03 00:00:00| 56.33047103881836| 56.46459197998047|    48.19384765625| 51.50214767456055| 44.29417037963867|4674300|3810883.3333333335|            2937500.0|               30|\n",
      "|     A|Agilent Technolog...|2000-01-04 00:00:00| 48.73032760620117| 49.26681137084961|46.316165924072266| 47.56795501708984| 40.91059112548828|4765000|3461913.3333333335|            2937500.0|               31|\n",
      "|     A|Agilent Technolog...|2000-01-05 00:00:00| 47.38912582397461| 47.56795501708984| 43.14198684692383|  44.6173095703125|38.372894287109375|5758600|3434606.6666666665|            2937500.0|               32|\n",
      "|     A|Agilent Technolog...|2000-01-06 00:00:00| 44.08082962036133| 44.34907150268555| 41.57725143432617|42.918453216552734| 36.91181564331055|2534400|         3319900.0|            2750800.0|               33|\n",
      "|     A|Agilent Technolog...|2000-01-07 00:00:00| 42.24785232543945| 47.16559219360352|42.203147888183594|46.494991302490234|39.987796783447266|2819600|3252446.6666666665|            2701750.0|               34|\n",
      "|     A|Agilent Technolog...|2000-01-10 00:00:00|49.356224060058594| 49.80329132080078| 48.32796859741211| 49.31151580810547| 42.41013717651367|2148400|3266413.3333333335|            2701750.0|               35|\n",
      "|     A|Agilent Technolog...|2000-01-11 00:00:00| 49.31151580810547| 49.31151580810547| 47.52324676513672| 48.64091491699219|41.833396911621094|1855900|3192453.3333333335|            2559150.0|               36|\n",
      "|     A|Agilent Technolog...|2000-01-12 00:00:00| 48.64091491699219| 48.64091491699219| 45.82439041137695| 47.65736770629883| 40.98748779296875|1429800|3096446.6666666665|            2431650.0|               37|\n",
      "|     A|Agilent Technolog...|2000-01-13 00:00:00|48.909156799316406| 49.93741226196289| 47.21030044555664|48.372676849365234| 41.60270309448242|1134300|         3035680.0|            2294150.0|               38|\n",
      "+------+--------------------+-------------------+------------------+------------------+------------------+------------------+------------------+-------+------------------+---------------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.parquet('../data/featuresAdded_stocks_etfs/A.parquet').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+----------+------------------+-----------------+------------------+------------------+------------------+-------+--------------+---------------------+\n",
      "|Symbol|       Security Name|      Date|              Open|             High|               Low|             Close|         Adj Close| Volume|vol_moving_avg|adj_close_rolling_med|\n",
      "+------+--------------------+----------+------------------+-----------------+------------------+------------------+------------------+-------+--------------+---------------------+\n",
      "|     A|Agilent Technolog...|1999-12-31| 56.86695098876953|57.17990112304688| 54.54220199584961| 55.30221557617188| 47.56241607666016|1931100|     5739950.0|            2937500.0|\n",
      "|     A|Agilent Technolog...|2000-01-03| 56.33047103881836|56.46459197998047|    48.19384765625| 51.50214767456055| 44.29417037963867|4674300|     3810883.0|            2937500.0|\n",
      "|     A|Agilent Technolog...|2000-01-04| 48.73032760620117|49.26681137084961|46.316165924072266| 47.56795501708984| 40.91059112548828|4765000|     3461913.0|            2937500.0|\n",
      "|     A|Agilent Technolog...|2000-01-05| 47.38912582397461|47.56795501708984| 43.14198684692383|  44.6173095703125|38.372894287109375|5758600|     3434607.0|            2937500.0|\n",
      "|     A|Agilent Technolog...|2000-01-06| 44.08082962036133|44.34907150268555| 41.57725143432617|42.918453216552734| 36.91181564331055|2534400|     3319900.0|            2750800.0|\n",
      "|     A|Agilent Technolog...|2000-01-07| 42.24785232543945|47.16559219360352|  42.2031478881836| 46.49499130249024| 39.98779678344727|2819600|     3252447.0|            2701750.0|\n",
      "|     A|Agilent Technolog...|2000-01-10|49.356224060058594|49.80329132080078| 48.32796859741211| 49.31151580810547| 42.41013717651367|2148400|     3266413.0|            2701750.0|\n",
      "|     A|Agilent Technolog...|2000-01-11| 49.31151580810547|49.31151580810547| 47.52324676513672| 48.64091491699219| 41.83339691162109|1855900|     3192453.0|            2559150.0|\n",
      "|     A|Agilent Technolog...|2000-01-12| 48.64091491699219|48.64091491699219| 45.82439041137695| 47.65736770629883| 40.98748779296875|1429800|     3096447.0|            2431650.0|\n",
      "|     A|Agilent Technolog...|2000-01-13|48.909156799316406|49.93741226196289| 47.21030044555664|48.372676849365234| 41.60270309448242|1134300|     3035680.0|            2294150.0|\n",
      "+------+--------------------+----------+------------------+-----------------+------------------+------------------+------------------+-------+--------------+---------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.parquet('../data/featuresAdded_stocks_etfs/A_featured.parquet/').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work_sample",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
